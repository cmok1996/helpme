# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10wwgJ0Ze3mDEVcf1QEqEVoK1ElOZCvRV
"""

pip install tensorflow

import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf  # now import the tensorflow module
print(tf.version)  # make sure the version is 2.x

string = tf.Variable("this is a string", tf.string)
number = tf.Variable(4, tf.int16)
floating = tf.Variable(3.5, tf.float64)

rank1_tensor = tf.Variable(["test", "ok", "chris"], tf.string)
rank2_tensor = tf.Variable([["test", "ok", "no"], ["test", "yes", "chris"]], tf.string)

tf.rank(rank2_tensor)

rank2_tensor.shape #2 list (dimensions), each list has 3 elements

tensor1 = tf.ones((1,2,3)) #1 interior list, 2lists inside that list, each list has 3 elements
print(tensor1) #6elements

tensor2 = tf.reshape(tensor1,[2,3,1]) #2list, 3 lists inside that list, each list has 1 element
print(tensor2)

tensor3 = tf.reshape(tensor2, [3, -1]) #tells the tensor to calculate the size of dimension in that place
print(tensor3)

t = tf.zeros([5,5,5,5]) #within each list, 5x5 matrix
print(t)

t = tf.reshape(t,[625])
print(t)

import matplotlib.pyplot as plt
import numpy as np

x = [1, 2, 2.5, 3, 4]
y = [1, 4, 7, 9, 15]
plt.plot(x, y, 'ro')
plt.axis([0, 6, 0, 20])
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))
plt.show()

!pip install -q sklearn

from __future__ import absolute_import, division, print_function, unicode_literals

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import clear_output
from six.moves import urllib

import tensorflow.compat.v2.feature_column as fc

import tensorflow as tf

# Load dataset.
dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data
y_train = dftrain.pop('survived') 
y_eval = dfeval.pop('survived')

print(type(dftrain))
print(y_train.loc[0])
print(dftrain.loc[0])

dftrain.describe()

dftrain.shape

dftrain.sex.value_counts().plot(kind='barh') #many more males than females

pd.concat([dftrain, y_train], axis=1).groupby("sex").survived.mean().plot(kind="barh").set_xlabel('% survive')
#Males have about 20% survival rate where female has 77%

CATEGORICAL_COLUMNS = ["sex", "n_siblings_spouses", "parch", "class", "deck", "embark_town", "alone"]
NUMERIC_COLUMNS =["age", "fare"]

#Convert categorical columns into dummy variables
feature_columns = [] #for the estimator function
for feature_name in CATEGORICAL_COLUMNS:
  vocabulary = dftrain[feature_name].unique() #gets a list of all unique values from given feature column
  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) #key, vocab_list

for feature_name in NUMERIC_COLUMNS:
  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))

print(feature_columns)

#Return function to make datasets so we can feed to the model

def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):
  def input_function():  # inner function, this will be returned
    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label
    if shuffle:
      ds = ds.shuffle(1000)  # randomize order of data
    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs
    return ds  # return a batch of the dataset
  return input_function  # return a function object for use

train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model
eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False) #test set only requires model to see once

#Creating the model - linear estimator
linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns) #takes feature columns as input

linear_est.train(train_input_fn)  # train, takes the training dataset input function as input
result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data by taking test dataset input function as input

clear_output()  # clears consoke output
print(result['accuracy'])  # the result variable is simply a dict of stats about# result = linear_est.evaluate(eval_input_fn) #get modle metrics/stats by testing on testing data

print(result)

result = list(linear_est.predict(eval_input_fn)) #list so you can loop, predict gives you the model-predicted outcome
print(result[0])

print(dfeval.loc[2])
print(y_eval.loc[2]) # 1 means survive
print(result[2]['probabilities'][1]) #1 prediction, access probability dictionary to see chance of survival

pred_dicts = list(linear_est.predict(eval_input_fn)) #Convert dictionary into a list
probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts]) # series of all the predicted probabilities by accessing individual dictionary. Each element contains a dictionary

probs.plot(kind='hist', bins=20, title='predicted probabilities')

from __future__ import absolute_import, division, print_function, unicode_literals


import tensorflow as tf

import pandas as pd

CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']
SPECIES = ['Setosa', 'Versicolor', 'Virginica']
# Lets define some constants to help us later on

train_path = tf.keras.utils.get_file(
    "iris_training.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
test_path = tf.keras.utils.get_file(
    "iris_test.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0) #specify that first row is the header
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)
# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe

train.head()

train_y = train.pop('Species')
test_y = test.pop('Species')
train.head() # the species column is now gone

train.shape  # we have 120 entires with 4 features

def input_fn(features, labels, training=True, batch_size=256):
    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels)) 

    # Shuffle and repeat if you are in training mode.
    if training:
        dataset = dataset.shuffle(1000).repeat()
    
    return dataset.batch(batch_size)
#Notice that this is different from the previous input function, it is not embedded inside another function

# Feature columns describe how to use the input.
my_feature_columns = []
for key in train.keys():
    my_feature_columns.append(tf.feature_column.numeric_column(key=key))
print(my_feature_columns)

# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.
classifier = tf.estimator.DNNClassifier(
    feature_columns=my_feature_columns,
    # Two hidden layers of 30 and 10 nodes respectively. Play around to optimize it
    hidden_units=[30, 10],
    # The model must choose between 3 classes.
    n_classes=3)

classifier.train(
    input_fn=lambda: input_fn(train, train_y, training=True),
    steps=5000) #instead of epoch, we specify the model to repeat until it sees 5000 observations
# We include a lambda to avoid creating an inner function previously. lambda allows to write a function when called. Lower loss, the better

eval_result = classifier.evaluate(
    input_fn=lambda: input_fn(test, test_y, training=False))

print('\nTest set accuracy: {accuracy:0.3f}\n'.format(**eval_result))

def input_fn(features, batch_size=256):
    # Convert the inputs to a Dataset without labels.
    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)

features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']
predict = {}

print("Please type numeric values as prompted.") #gives you the prompt
for feature in features:
  valid = True
  while valid: #if not valid response, repeat prompt
    val = input(feature + ": ")
    if not val.isdigit(): valid = False

  predict[feature] = [float(val)] #have to put inside a list as tensorflow expects a list. Creates a dictionary inside the list for each feature

predictions = classifier.predict(input_fn=lambda: input_fn(predict))
for pred_dict in predictions: #Each element is a dictionary
    print(pred_dict)
    class_id = pred_dict['class_ids'][0] #returns the label predicted by model
    probability = pred_dict['probabilities'][class_id]

    print('Prediction is "{}" ({:.1f}%)'.format(
        SPECIES[class_id], 100 * probability))

# Here is some example input and expected classes you can try above
expected = ['Setosa', 'Versicolor', 'Virginica']
predict_x = {
    'SepalLength': [5.1, 5.9, 6.9],
    'SepalWidth': [3.3, 3.0, 3.1],
    'PetalLength': [1.7, 4.2, 5.4],
    'PetalWidth': [0.5, 1.5, 2.1],
}

!pip install tensorflow_probability==0.8.0rc0 --user --upgrade

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x  # this line is not required unless you are in a notebook

import tensorflow_probability as tfp  # We are using a different module from tensorflow this time
import tensorflow as tf #difficulty in running

tfd = tfp.distributions  # making a shortcut for later on
initial_distribution = tfd.Categorical(probs=[0.2, 0.8])  # Refer to point 2 above, initial state has probability of 0.2 hot and 0.8 cold. 2 states, 0=hot, 1=cold
transition_distribution = tfd.Categorical(probs=[[0.7, 0.3], #Transition distribution following hot day, 0.7 hot and 0.3 cold, point 3
                                                 [0.2, 0.8]])  #Transition ditribution following cold day, 0.2 hot and 0.8 cold, point 4
observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above, use float values .

# the loc argument represents the mean and the scale is the standard devitation (range)

model = tfd.HiddenMarkovModel(
    initial_distribution=initial_distribution,
    transition_distribution=transition_distribution,
    observation_distribution=observation_distribution,
    num_steps=7) #steps in number of periods ahead to be forecasted

mean = model.mean()

# due to the way TensorFlow works on a lower level we need to evaluate part of the graph
# from within a session to see the value of this tensor

# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()
with tf.compat.v1.Session() as sess:  
  print(mean.numpy())

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x  # this line is not required unless you are in a notebook
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = keras.datasets.fashion_mnist  # load dataset from keras

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training, stored as tuples

train_images.shape #60000 images, each made up of 28x28 pixels (784 in total)

train_images[0,23,23]  # let's have a look at one pixel #Our pixel values are between 0 and 255, 0 being black and 255 being white. This means we have a grayscale image as there are no color channels.

type(train_images) #array of 60,000 images

train_labels[:10]  # let's have a look at the first 10 training labels

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

#Take a look at what each image looks like
plt.figure()
plt.imshow(train_images[1])
plt.colorbar()
plt.grid(False)
plt.show()

train_images = train_images / 255.0

test_images = test_images / 255.0 #important to pre-process both. Pre-process as values of weights and biases are between 0-1, easier to handle

#Model architecture. Can change the number of nodes in hidden layer as well as type of activation function
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),  # input layer (1), flatten converts matrix to single array
    keras.layers.Dense(128, activation='relu'),  # hidden layer (2), specify 128 nodes in hidden layer, relu returns 0 for negative and y=x for positive
    keras.layers.Dense(10, activation='softmax') # output layer (3), number of nodes = number of classes. Softmax ensures probability adds up to 1, and squish value between 1
])

#hyperparemeter tuning, different functions can be specified
model.compile(optimizer='adam', #Gradient descent to minimize loss fnction
              loss='sparse_categorical_crossentropy', #the loss function
              metrics=['accuracy']) #see the accuracy, confusion matrix

#specify number of epochs, another parameter we can tune
#too many epochs can lead to overfitting. Situation where training accuracy > test accuracy
model.fit(train_images, train_labels, epochs=10)  # we pass the data, labels and epochs and watch the magic!

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) #verbose just shows the progress bar

print('Test accuracy:', test_acc) #to improve accuracy, change the parameters (epochs, optimization, loss, number of nodes in hidden layers, etc)

# Making predictions

predictions = model.predict(test_images) #make sure input is a list as predict is better at predicting multiple things at once
print(predictions[0]) #returns 10 different probabilities according to the different classifications above
print(class_names[np.argmax(predictions[0])])
plt.figure()
plt.imshow(test_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

COLOR = 'black'
plt.rcParams['text.color'] = COLOR
plt.rcParams['axes.labelcolor'] = COLOR

def predict(model, image, correct_label):
  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
  prediction = model.predict(np.array([image]))
  predicted_class = class_names[np.argmax(prediction)]

  show_image(image, class_names[correct_label], predicted_class)


def show_image(img, label, guess):
  plt.figure()
  plt.imshow(img)
  plt.title("Excpected: " + label)
  plt.xlabel("Guess: " + guess)
  plt.colorbar()
  plt.grid(False)
  plt.show()


def get_number():
  while True:
    num = input("Pick a number: ")
    if num.isdigit():
      num = int(num)
      if 0 <= num <= 1000:
        return int(num)
    else:
      print("Try again...")

num = get_number()
image = test_images[num]
label = test_labels[num]
predict(model, image, label)

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x  # this line is not required unless you are in a notebook
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

#  LOAD AND SPLIT DATASET
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Let's look at a one image
IMG_INDEX = 7  # change this to look at other images

plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)
plt.xlabel(class_names[train_labels[IMG_INDEX][0]])
plt.show()

# common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. 
#To idea is that the stack of convolutional and maxPooling layers extract the features from the image. 
#Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) #The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.
model.add(layers.MaxPooling2D((2, 2))) #This layer will perform the max pooling operation using 2x2 samples and a stride of 2.
model.add(layers.Conv2D(64, (3, 3), activation='relu')) #  increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth. Automatically figure out the input shape. 
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.summary()  # let's have a look at our model so far. no padding, hence dimensionality for conv2d drops. Dimensionality reduces by factor of 2 when pooling. These are the convolutional base

#Adding dense layers
model.add(layers.Flatten()) #from 4,4,64 into one single array
model.add(layers.Dense(64, activation='relu')) #conventional
model.add(layers.Dense(10)) #number of classifications

#We can see that the flatten layer changes the shape of our data so that we can feed it to the 64-node dense layer, follwed by the final output layer of 10 neurons (one for each class).
model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #standard loss
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=4, #takes long time
                    validation_data=(test_images, test_labels))

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print(test_acc)

#Augmentation
#To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. 
# This is simply performing random transofrmations on our images so that our model can generalize better. 
# These transformations can be things like compressions, rotations, stretches and even color changes.
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

# creates a data generator object that transforms images
datagen = ImageDataGenerator(
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True,
fill_mode='nearest')

# pick an image to transform
test_img = train_images[20]
img = image.img_to_array(test_img)  # convert image to numpy array
img = img.reshape((1,) + img.shape)  # reshape image

i = 0

for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix
    plt.figure(i)
    plot = plt.imshow(image.img_to_array(batch[0])) #convert dataset to numpy array
    i += 1
    if i > 4:  # show 4 images
        break

plt.show()

#Using pre-trained model
#Imports
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
keras = tf.keras

import tensorflow_datasets as tfds
tfds.disable_progress_bar()

# split the data manually into 80% training, 10% testing, 10% validation
#Loading data is unique to data type, check the syntax
(raw_train, raw_validation, raw_test), metadata = tfds.load(
    'cats_vs_dogs',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels
# display 5 images from the dataset
for image, label in raw_train.take(5): #take 5 images, different dimensions
  plt.figure()
  plt.imshow(image)
  plt.title(get_label_name(label))

#Since the sizes of our images are all different, we need to convert them all to the same size. We can create a function that will do that for us below.

IMG_SIZE = 160 # All images will be resized to 160x160

def format_example(image, label):
  """
  returns an image that is reshaped to IMG_SIZE
  """
  image = tf.cast(image, tf.float32) #converts tensor object into an array of floats
  image = (image/127.5) - 1 #127.5 being half of 255 pixels
  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  return image, label

train = raw_train.map(format_example) #for each element in raw_train, apply the function
validation = raw_validation.map(format_example)
test = raw_test.map(format_example)

for image, label in train.take(2):
  plt.figure()
  plt.imshow(image)
  plt.title(get_label_name(label))

#shuffle and batch the images
BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)

for img, label in raw_train.take(2): #3 layers, red green blue
  print("Original shape:", img.shape)

for img, label in train.take(2):
  print("New shape:", img.shape)

IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)

# Create the base model from the pre-trained model MobileNet V2
# This model is trained on 1.4 million images and has 1000 different classes.
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, #specify our input shape
                                               include_top=False,
                                               weights='imagenet')

base_model.summary()
#At this point this base_model will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of differnt filters/features.

for image, _ in train_batches.take(1):
   pass

feature_batch = base_model(image)
print(feature_batch.shape) #1280 layers

#Freeze the base means we wonâ€™t make any changes to the weights of any layers that are frozen during training
base_model.trainable = False

base_model.summary() #0 trainable parameters

#Now that we have our base layer setup, we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter.
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
global_average_layer

#Finally, we will add the predicition layer that will be a single dense neuron. We can do this because we only have two classes to predict for.
prediction_layer = keras.layers.Dense(1)

#combine the models
model = tf.keras.Sequential([
  base_model,
  global_average_layer,
  prediction_layer
])

model.summary()

base_learning_rate = 0.0001 #small learning rate as the pre-trained model is already capable of classifying 1000 images
model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #binary because only 2 classifications
              metrics=['accuracy'])

# We can evaluate the model right now to see how it does before training it on our new images
#as good as random
initial_epochs = 3
validation_steps=20

loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)

# Now we can train it on our images, observe that accuracy significantly improves
history = model.fit(train_batches,
                    epochs=initial_epochs,
                    validation_data=validation_batches)

acc = history.history['accuracy']
print(acc)

model.save("dogs_vs_cats.h5")  # we can save the model and reload it at anytime in the future
new_model = tf.keras.models.load_model('dogs_vs_cats.h5') #takes a long time to load

#Bag of words
#Not the same in practice
#dict[key] access the vocab
vocab = {}  # maps word to integer representing it
word_encoding = 1
def bag_of_words(text):
  global word_encoding

  words = text.lower().split(" ")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example
  bag = {}  # stores all of the encodings and their frequency

  for word in words:
    if word in vocab:
      encoding = vocab[word]  # get encoding from vocab
    else:
      vocab[word] = word_encoding #makes word the key
      encoding = word_encoding
      word_encoding += 1
    
    if encoding in bag:
      bag[encoding] += 1 #encoding is the key, counter is the vocab
    else:
      bag[encoding] = 1
  
  return bag

text = "this is a test to see if this test will work is is test a a"
bag = bag_of_words(text)
print(bag)
print(vocab)

vocab = {}  
word_encoding = 1
def one_hot_encoding(text):
  global word_encoding

  words = text.lower().split(" ") 
  encoding = []  

  for word in words:
    if word in vocab:
      code = vocab[word]  
      encoding.append(code) 
    else:
      vocab[word] = word_encoding
      encoding.append(word_encoding)
      word_encoding += 1
  
  return encoding

text = "this is a test to see if this test will work is is test a a"
encoding = one_hot_encoding(text)
print(encoding)
print(vocab)

positive_review = "I thought the movie was going to be bad but it was actually amazing"
negative_review = "I thought the movie was going to be amazing but it was actually bad"

pos_encode = one_hot_encoding(positive_review)
neg_encode = one_hot_encoding(negative_review)

print("Positive:", pos_encode)
print("Negative:", neg_encode)

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x  # this line is not required unless you are in a notebook
from keras.datasets import imdb
from keras.preprocessing import sequence
import keras
import tensorflow as tf
import os
import numpy as np

# loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative.
# Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset.
VOCAB_SIZE = 88584 #number of unique words, each word correspond to an int

MAXLEN = 250
BATCH_SIZE = 64

(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)

# Lets look at one review
train_data[1]

#More preprocessing
#if the review is greater than 250 words then trim off the extra words
#if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.
train_data = sequence.pad_sequences(train_data, MAXLEN)
test_data = sequence.pad_sequences(test_data, MAXLEN)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(VOCAB_SIZE, 32), #simple RNN
    tf.keras.layers.LSTM(32), #number of outputs in simple RNN
    tf.keras.layers.Dense(1, activation="sigmoid") #binary classification, just 1 node
])

model.summary()

#Training the model
model.compile(loss="binary_crossentropy",optimizer="rmsprop",metrics=['acc']) #adam optimizer works fine too

history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2) #leave 20% of training set as validation data

results = model.evaluate(test_data, test_labels)
print(results)

word_index = imdb.get_word_index() #do the padding and all,  a dictionary

def encode_text(text): #convert text into int array that model understands
  tokens = keras.preprocessing.text.text_to_word_sequence(text) #convert a sentence into its individual words
  print(tokens)
  tokens = [word_index[word] if word in word_index else 0 for word in tokens] #word_index[word] returns the encoding in the dictionary / training set. for each word in tokens, store into word_index
  print(tokens)
  return sequence.pad_sequences([tokens], MAXLEN)[0] #process, then prints out a list, just want the first element

text = "that movie was just amazing, so amazing"
encoded = encode_text(text)
print(encoded)

# while were at it lets make a decode function
# convert int arrays into text

reverse_word_index = {value: key for (key, value) in word_index.items()}

def decode_integers(integers):
    PAD = 0
    text = ""
    for num in integers:
      if num != PAD:
        text += reverse_word_index[num] + " "

    return text[:-1]
  
print(decode_integers(encoded))

# now time to make a prediction

def predict(text):
  encoded_text = encode_text(text) #pre-process the text first
  pred = np.zeros((1,250)) #250 words for processing, create storage array
  pred[0] = encoded_text #all 0, unless there is a word
  #print(pred)
  result = model.predict(pred) #returns a probability. 0 is negative, 1 is good
  print(result[0])

#model 'kinda understand the predictive power of words'. Removing basic texts like 'that' would not change the rating much
positive_review = "That movie was great! really loved it and would great watch it again because it was amazingly great"
predict(positive_review) #0 is negative, 1 is good

negative_review = "that movie really bad. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched"
predict(negative_review)

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x  # this line is not required unless you are in a notebook
from keras.preprocessing import sequence
import keras
import tensorflow as tf
import os
import numpy as np

#Poem RNN example
#load the shakespeare poem from the shared drive into this collab
path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')

#upload from own computer
from google.colab import files
path_to_file = list(files.upload().keys())[0]

# Read, then decode for py2 compat.
text = open(path_to_file, 'rb').read().decode(encoding='utf-8')
# length of text is the number of characters in it
print ('Length of text: {} characters'.format(len(text))) #individual characters, not words

# Take a look at the first 250 characters in text
print(text[:250])

#encoding based on characters as they are finite compared to words
vocab = sorted(set(text)) #returns the unique set of characters, sorted from special characters to A-Z
print(vocab)
# Creating a mapping from unique characters to indices
char2idx = {u:i for i, u in enumerate(vocab)} #enumerate returns [index, string]. For loop i = index, u = string. Store in dict with {string:index}
idx2char = np.array(vocab) #convert the dict keys into array

def text_to_int(text): #convert the play into integers by looping each character in text, and store into array
  return np.array([char2idx[c] for c in text]) 

text_as_int = text_to_int(text)

# lets look at how part of our text is encoded, first 13 characters
print("Text:", text[:13])
print("Encoded:", text_to_int(text[:13]))

#And here we will make a function that can convert our numeric values to text.
def int_to_text(ints):
  try:
    ints = ints.numpy() #make sure it is numpy format, otherwise do nothing
  except:
    pass
  return ''.join(idx2char[ints]) #access the array by its index of the keys

print(int_to_text(text_as_int[:13]))

#Creating training examples
#Remember our task is to feed the model a sequence and have it return to us the next character. 
#This means we need to split our text data from above into many shorter sequences that we can pass to the model as training examples.
#The training examples we will prepapre will use a seq_length sequence as input and a seq_length sequence as the output where that sequence is the original sequence shifted one letter to the right
#Create a stream of characters for our data

seq_length = 100  # length of sequence for a training example, 1 example has 100 characters
examples_per_epoch = len(text)//(seq_length+1) #101 since need to plus/minus 1 from start/end
print(examples_per_epoch) #number of training data

# Create training examples / targets
char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) #play in integers

#use the batch method to turn this stream of characters into batches of desired length.
sequences = char_dataset.batch(seq_length+1, drop_remainder=True)
print(type(sequences))

#Now we need to use these sequences of length 101 and split them into input and output
def split_input_target(chunk):  # for the example: hello
    input_text = chunk[:-1]  # hell
    target_text = chunk[1:]  # ello
    return input_text, target_text  # hell, ello

dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry of the batch dataset
print(type(dataset))
dataset.take(2)

for x, y in dataset.take(2): #input and output from dataset, 2 ranks
  print("\n\nEXAMPLE\n")
  print("INPUT")
  print(int_to_text(x))
  print("\nOUTPUT")
  print(int_to_text(y))

#Make training batches

BATCH_SIZE = 64 #each batch has 100 characters
VOCAB_SIZE = len(vocab)  # vocab is number of unique characters
EMBEDDING_DIM = 256
RNN_UNITS = 1024

# Buffer size to shuffle the dataset
# (TF data is designed to work with possibly infinite sequences,
# so it doesn't attempt to shuffle the entire sequence in memory. Instead,
# it maintains a buffer in which it shuffles elements).
BUFFER_SIZE = 10000

data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True) #if bag has 105 characters, drop the remaining

#Now it is time to build the model. We will use an embedding layer a LSTM and one dense layer that contains a node for each unique character in our training data.
#The dense layer will give us a probability distribution over all nodes.
def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim,
                              batch_input_shape=[batch_size, None]), #when we use the model to predict, we won't know the length of the batches (64 batches). It might not be 100. Hence we put none
    tf.keras.layers.LSTM(rnn_units,
                        return_sequences=True, #to see every output, instead of just the final output
                        stateful=True,
                        recurrent_initializer='glorot_uniform'), #the default
    tf.keras.layers.Dense(vocab_size) #number of unique characters, give us a probability distribution for each character
  ])
  return model

model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)
model.summary() #64 batches, length none, number of dense nodes

#Take a look at output
for input_example_batch, target_example_batch in data.take(1):
  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)
  print(example_batch_predictions.shape, "# (batch_size, sequence_length, vocab_size)")  # print out the output shape, length 100

# we can see that the predicition is an array of 64 arrays, one for each entry in the batch
print(len(example_batch_predictions)) #64
#print(example_batch_predictions) #[[], [],... 64 times]

# lets examine one prediction
pred = example_batch_predictions[0]
print(len(pred)) #100 different arrays nested in an array
print(pred) #[[65ints], [65ints],...100 times]
# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step

# and finally well look at a prediction at the first timestep
time_pred = pred[0]
print(len(time_pred))
print(time_pred)
# and of course its 65 values representing the probabillity of each character occuring next

# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)
sampled_indices = tf.random.categorical(pred, num_samples=1) #sample the interior array from the 100 different arrays

# now we can reshape that array and convert all the integers to numbers to see the actual characters
sampled_indices = np.reshape(sampled_indices, (1,-1))[0] #1 shape dimension is denoted by -1, [0] returns the interior loop of the nested loop
#print(sampled_indices)
predicted_chars = int_to_text(sampled_indices)

predicted_chars  # and this is what the model predicted for training sequence 1, 1 character from each of 100 time stamps

#Create loss function
#Now we are going to create our own loss function for this problem. 
#This is because our model will output a (64, sequence_length, 65) shaped tensor that represents the probability distribution of each character at each timestep for every sequence in the batch.

def loss(labels, logits):
  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)

#Compile the model
model.compile(optimizer='adam', loss=loss)

# Creating checkpoints. This will allow us to load our model from a checkpoint and continue training it.

#Directory where the checkpoints will be saved
checkpoint_dir = './training_checkpoints'
# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}") #epoch

checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_prefix,
    save_weights_only=True)

#Train the model, can go for high epoch as it is unlikely to overfit
history = model.fit(data, epochs=50, callbacks=[checkpoint_callback]) #ensure callbacks is called

#Need to rebuild the model to accept batch-size = 1
model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)

#Once the model is finished training, we can find the lastest checkpoint that stores the models weights using the following line
model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
model.build(tf.TensorShape([1, None])) #build the model to accept 1 batch of unknown length

#We can load any checkpoint we want by specifying the exact file to load.
checkpoint_num = 10
model.load_weights(tf.train.load_checkpoint("./training_checkpoints/ckpt_" + str(checkpoint_num)))
model.build(tf.TensorShape([1, None]))

#Form predictions

def generate_text(model, start_string):
  # Evaluation step (generating text using the learned model)

  # Number of characters to generate
  num_generate = 800

  # Converting our start string to numbers (vectorizing)
  input_eval = [char2idx[s] for s in start_string] #encode into integers
  input_eval = tf.expand_dims(input_eval, 0) #converts list into a nested list, to add one more dimension, as that is what the model expects [[]]

  # Empty string to store our results
  text_generated = []

  # Low temperatures results in more predictable text.
  # Higher temperatures results in more surprising text.
  # Experiment to find the best setting.
  temperature = 1.0

  # Here batch size == 1
  model.reset_states() #need to reset the state as the model would have remembered the previous state when training the model
  for i in range(num_generate):
      predictions = model(input_eval)
      # remove the batch dimension
    
      predictions = tf.squeeze(predictions, 0) #converts [[]] into []

      # using a categorical distribution to predict the character returned by the model
      predictions = predictions / temperature
      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy() #need to sample the distribution

      # We pass the predicted character as the next input to the model
      # along with the previous hidden state
      input_eval = tf.expand_dims([predicted_id], 0)

      text_generated.append(idx2char[predicted_id]) #converts the encoded integers into text

  return (start_string + ''.join(text_generated))

#Reinforcement learning
import gym   # all you have to do to import and use open ai gym!

env = gym.make('FrozenLake-v0')  # we are going to use the FrozenLake enviornment

print(env.observation_space.n)   # get number of states
print(env.action_space.n)   # get number of actions

env.reset()  # reset enviornment to default state

action = env.action_space.sample()  # get a random action

new_state, reward, done, info = env.step(action)  # take action, notice it returns information about the action. done is when it dies

#16 states (one for each square)
#4 possible actions (LEFT, RIGHT, DOWN, UP)
#4 different types of blocks (F: frozen, H: hole, S: start, G: goal
env.render()   # render the GUI for the enviornment. S is starting, F is frozen, H is hole, G is goal

import gym
import numpy as np
import time

env = gym.make('FrozenLake-v0')
STATES = env.observation_space.n
ACTIONS = env.action_space.n

#initialize the q table
Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values 
Q

EPISODES = 2000 # how many times to run the enviornment from the beginning
MAX_STEPS = 100  # max number of steps allowed for each run of enviornment, before it breaks into next episode

LEARNING_RATE = 0.81  # learning rate
GAMMA = 0.96

#Pick an action
#1.Randomly picking a valid action
#2.Using the current Q-Table to find the best action.
epsilon = 0.9  # start with a 90% chance of picking a random action

# code to pick action
if np.random.uniform(0, 1) < epsilon:  # we will check if a randomly selected value is less than epsilon.
    action = env.action_space.sample()  # take random action
else:
    action = np.argmax(Q[state, :])  # use Q table to pick best action based on current values

#putting it together
import gym
import numpy as np
import time

env = gym.make('FrozenLake-v0')
STATES = env.observation_space.n
ACTIONS = env.action_space.n

Q = np.zeros((STATES, ACTIONS))

EPISODES = 1500 # how many times to run the enviornment from the beginning
MAX_STEPS = 100  # max number of steps allowed for each run of enviornment

LEARNING_RATE = 0.81  # learning rate is high because we start with 0s
GAMMA = 0.96

RENDER = False # if you want to see, set to true

epsilon = 0.9

rewards = []
for episode in range(EPISODES):

  state = env.reset()
  for _ in range(MAX_STEPS):
    
    if RENDER: #set to false for now
      env.render()

    if np.random.uniform(0, 1) < epsilon: #picking an action
      action = env.action_space.sample()  
    else:
      action = np.argmax(Q[state, :]) #argmax looks at the current state

    next_state, reward, done, _ = env.step(action)

    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[next_state, :]) - Q[state, action]) #updating q table

    state = next_state

    if done: 
      rewards.append(reward)
      epsilon -= 0.001 #slowly change the epsilon so agent follows q-table rather than random action
      break  # reached goal

print(Q)
print(f"Average reward: {sum(rewards)/len(rewards)}:") #for each episode, 1 reward
# and now we can see our Q values!

# we can plot the training progress and see how the agent improved
import matplotlib.pyplot as plt

def get_average(values):
  return sum(values)/len(values)

avg_rewards = []
for i in range(0, len(rewards), 100):
  avg_rewards.append(get_average(rewards[i:i+100])) 

plt.plot(avg_rewards)
plt.ylabel('average reward')
plt.xlabel('episodes (100\'s)')
plt.show()

#See interaction

state = env.reset()
for _ in range(MAX_STEPS):
  action = np.argmax(Q[state, :]) #argmax looks at the current state
  next_state, reward, done, _ = env.step(action)

#Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[next_state, :]) - Q[state, action]) #updating q table

  state = next_state


print(rewards)
#print(f"Average reward: {sum(rewards)/len(rewards)}:") #for each episode, 1 reward
# and now we can see our Q values!

