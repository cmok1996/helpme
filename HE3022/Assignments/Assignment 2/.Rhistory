fit.lin <- tslm(marathon ~ trend)
autoplot(marathon) +
forecast::autolayer(fitted(fit.lin), series = "Linear") +
xlab("Year") + ylab("Winning times in minutes")
res.mar <- residuals(tslm(marathon ~ trend))
autoplot(res.mar)+
xlab("Year") + ylab("Residuals from a linear trend")
h <- 10
fit.lin <- tslm(marathon ~ trend)
fcasts.lin <- forecast(fit.lin, h=h)
fit.exp <- tslm(marathon ~ trend, lambda = 0) #boxcox with lamda=0 is just a log function
fcasts.exp <- forecast(fit.exp, h=h)
t <- time(marathon)
t.break1 <- 1940
t.break2 <- 1980
t1 <- ts(pmax(0,t-t.break1), start=1897) #pmax specifies the equation in piecewise format
t2 <- ts(pmax(0,t-t.break2), start=1897)
t <- time(marathon)
t.break1 <- 1940
t.break2 <- 1980
t1 <- ts(pmax(0,t-t.break1), start=1897) #pmax specifies the equation in piecewise format
t2 <- ts(pmax(0,t-t.break2), start=1897)
fit.pw <- tslm(marathon ~ t * t1 + t2)
t.new <- t[length(t)]+seq(h)
t1.new <- t1[length(t1)]+seq(h)
t2.new <- t2[length(t2)]+seq(h)
newdata <- cbind(t=t.new,t1=t1.new,t2=t2.new)%>%as.data.frame()
fcasts.pw <- forecast(fit.pw,newdata = newdata)
autoplot(marathon) +
forecast::autolayer(fitted(fit.lin), series = "Linear") +
forecast::autolayer(fitted(fit.exp), series="Exponential") +
forecast::autolayer(fitted(fit.pw), series = "Piecewise") +
forecast::autolayer(fcasts.pw, series="Piecewise") +
forecast::autolayer(fcasts.lin$mean, series = "Linear") +
forecast::autolayer(fcasts.exp$mean, series="Exponential") +
xlab("Year") + ylab("Winning times in minutes") +
ggtitle("Boston Marathon") +
guides(colour=guide_legend(title=" "))
checkresiduals(fit.pw)
seq(h)
t1.new
length(t)
t[length(t)]
t1
t2
newdata
autoplot(marathon) +
forecast::autolayer(fitted(fit.lin), series = "Linear") +
forecast::autolayer(fitted(fit.exp), series="Exponential") +
forecast::autolayer(fitted(fit.pw), series = "Piecewise") +
forecast::autolayer(fcasts.pw, series="Piecewise") +
forecast::autolayer(fcasts.lin$mean, series = "Linear") +
forecast::autolayer(fcasts.exp$mean, series="Exponential") +
xlab("Year") + ylab("Winning times in minutes") +
ggtitle("Boston Marathon") +
guides(colour=guide_legend(title=" "))
t*t1
fit.pw
fit.pw <- tslm(marathon ~ t + t1 + t2)
t.new <- t[length(t)]+seq(h)
t1.new <- t1[length(t1)]+seq(h)
t2.new <- t2[length(t2)]+seq(h)
newdata <- cbind(t=t.new,t1=t1.new,t2=t2.new)%>%as.data.frame()
fcasts.pw <- forecast(fit.pw,newdata = newdata)
autoplot(marathon) +
forecast::autolayer(fitted(fit.lin), series = "Linear") +
forecast::autolayer(fitted(fit.exp), series="Exponential") +
forecast::autolayer(fitted(fit.pw), series = "Piecewise") +
forecast::autolayer(fcasts.pw, series="Piecewise") +
forecast::autolayer(fcasts.lin$mean, series = "Linear") +
forecast::autolayer(fcasts.exp$mean, series="Exponential") +
xlab("Year") + ylab("Winning times in minutes") +
ggtitle("Boston Marathon") +
guides(colour=guide_legend(title=" "))
#time series decomposition
fit <- stl(elecequip, s.window="periodic")
plot(elecequip, col="gray", main="Electical equipment manufacturing",
ylab="New orders index", xlab="")
lines(trendcycle(fit),col="red",yab="Trend-Cycle")
plot(fit)
#seasonally adjusted data just removes the seasonality component. Macroeconomic data
plot(elecequip, col="grey",
main="Equipment manufacturing", xlab="", ylab="New orders index")
lines(seasadj(fit),col="red",ylab="Seasonally adjusted")
#Use moving averages to extract trend cycle
data.vec <- round(rnorm(10)*100) #default is round off to nearest whole number
table.out <- rbind(data.vec, ma(data.vec, order=5))
rownames(table.out) <- c("data","5-MA")
table.out
data.vec
autoplot(elecsales, series="Data") +
forecast::autolayer(ma(elecsales,5), series="5-MA") +
xlab("Year") + ylab("GWh") +
ggtitle("Annual electricity sales: South Australia") +
scale_colour_manual(values=c("Data"="grey50","5-MA"="red"),
breaks=c("Data","5-MA"))
ma5 <- ma(elecsales, 5)
table.out <- rbind(elecsales, ma5)
rownames(table.out) <- c("sales(GWh)", "5-MA") table.out
rownames(table.out) <- c("sales(GWh)", "5-MA")
table.out
autoplot(elecequip, series="Data") +
autolayer(ma(elecequip, 12, centre = FALSE), series="12-MA") +
xlab("Year") + ylab("New orders index") +
ggtitle("Electrical equipment manufacturing (Euro area)") +
scale_colour_manual(values=c("Data"="grey","12-MA"="red"),
breaks=c("Data","12-MA"))
elecequip %>% decompose(type="multiplicative") %>%
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition of elec equip index")
#Multiplicative Decomposition is used if variation changes as level changes - there is proportionalit
elecequip %>% decompose(type="additive") %>% #if type additi
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition of elec equip index")
#Multiplicative Decomposition is used if variation changes as level changes - there is proportionalit
elecequip %>% decompose(type="multiplicative") %>% #if type additi
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition of elec equip index")
#Multiplicative Decomposition is used if variation changes as level changes - there is proportionalit
elecequip %>% decompose(type="additive") %>% #if type additi
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition of elec equip index")
#Multiplicative Decomposition is used if variation changes as level changes - there is proportionalit
elecequip %>% decompose(type="multiplicative") %>% #if type additive, the variation of seasonality will change
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition of elec equip index")
#X-11 decomposition applies Spencer or Henderson to include missing data & allow seasonal component to vary slowly with time
library(seasonal)
#X-11 decomposition applies Spencer or Henderson to include missing data & allow seasonal component to vary slowly with time
library("seasonal")
#X-11 decomposition applies Spencer or Henderson to include missing data & allow seasonal component to vary slowly with time
library(fpp2)
library(seasonal)
#library(seasonal)
#Fluctuation is due to remainder component, hardly any variation within seasons
install("X12")
#library(seasonal)
#Fluctuation is due to remainder component, hardly any variation within seasons
install.packages("X12")
#library(seasonal)
#Fluctuation is due to remainder component, hardly any variation within seasons
install.packages("x12")
library(seasonal)
#Fluctuation is due to remainder component, hardly any variation within seasons
install.packages("fpp2")
library(seasonal)
library('seasonal')
install.packages("seasonal")
library(seasonal)
fit2<-seas(elecequip, x11="")
autoplot(fit2) +  ggtitle("X11 decomposition of electrical equipment index")
autoplot(elecequip, series="Data") +
forecast::autolayer(trendcycle(fit2), series="Trend") +
forecast::autolayer(seasadj(fit2), series="Seasonally Adjusted") +
xlab("Year") + ylab("New orders index") +
ggtitle("Electrical equipment manufacturing (Euro area)") +
scale_colour_manual(values=c("gray","blue","red"),
breaks=c("Data","Seasonally Adjusted","Trend"))
ggsubseriesplot(seasonal(fit2)) + ylab("Seasonal") +
ggtitle("Sub-series plot: Electrical equipment manufacturing (Euro area)")
elecequip %>%
stl(t.window=13, s.window="periodic", robust=TRUE) #robust to outliers
%>%  autoplot
elecequip %>%
stl(t.window=13, s.window="periodic", robust=TRUE) %>% #robust to outliers
autoplot
#forecasting
fit <- stl(elecequip, t.window=13, s.window="periodic", robust=TRUE)
fit %>% seasadj() %>% naive() %>% autoplot() + ylab("New orders index") + xlab("year") +
ggtitle("Naive forecasts of seasonally adjusted data")
fit %>% forecast(method="naive") %>% autoplot() + ylab("New orders index") #to add the seasonality back into the forecast
#shortcut is to use stlf
fcast <- stlf(elecequip, method="naive")
autoplot(fcast)
library(fpp2)
oildata <- window(oil, start=1996)
autoplot(oildata) +
ylab("Oil (millions of tonnes") + xlab("Year")+
ggtitle("Saudi Arabia oil production")
#the larger the weight, the more importance is given to the more recent observation
#alpha = 1 is simply a naive model
#alpha and lamda is decided by the user
fc <- ses(oildata, h=5) #ses gives us the simple exponential smoothing model
round(accuracy(fc),2) #get error forecast
summary(fc)
oildata
oil
oildata
autoplot(fc) +
forecast::autolayer(fitted(fc), series="Fitted") +
ylab("Oil (millions of tonnes)") + xlab("Year")
library(fpp2)
plot(elec) #increasing variation
lambda <- BoxCox.lambda(elec) #calculate lambda = 0.27
rm(lis=ls())
rm(list=ls())
?rwf
#When we back transform, we will get the median, leads to bias
fc <- rwf(eggs, drift=TRUE, lambda=0, h=50, level=80) #returns forecast ad predicton interval for random walk with drift model
fc
#difference between fc & fc2 is the adjustment of bias. fc gives median, fc2 gives mean forecast
autoplot(eggs) +
forecast::autolayer(fc$mean, series="Simple back transformation") +
forecast::autolayer(fc2$mean, series="Bias adjusted") +
guides(colour=guide_legend(title="Forecast")) #if we omit the $mean, it gives prediction interval
fc2 <- rwf(eggs, drift=TRUE, lambda=0, h=50, level=80, biasadj=TRUE) #lambda = 0 gives log transformation, h is the period forecast ahead
#difference between fc & fc2 is the adjustment of bias. fc gives median, fc2 gives mean forecast
autoplot(eggs) +
forecast::autolayer(fc$mean, series="Simple back transformation") +
forecast::autolayer(fc2$mean, series="Bias adjusted") +
guides(colour=guide_legend(title="Forecast")) #if we omit the $mean, it gives prediction interval
#greater the h, greater the bias. Formula is a function of h
autoplot(fc2)+
ggtitle("Biased adjusted transformed")
#Calendar adjustments - eg, CNY, stock market zero observation. February has fewer days, thus production is less
dframe <- cbind(Monthly = milk, DailyAverage = milk/monthdays(milk)) #cbind combines 2 series output, store in dframe object. monthdays adjust different days each month
dframe
milk
autoplot(dframe, facet=TRUE) + xlab("Years") + ylab("Pounds") +
ggtitle("Milk production per cow") #effectively remove the variation due to different month lengths
dj2 <- window(dj, end=250)
autoplot(dj2) + xlab("Day") + ylab("") +
ggtitle("Dow Jones Index (daily ending 15 Jul 94)")
res <- residuals(naive(dj2)) #et = yt-yt-1
autoplot(res) + xlab("Day") + ylab("") +
ggtitle("Residuals from naive method") #looks random, no seasonality. residual mean close to zero
gghistogram(res) + ggtitle("Histogram of residuals") #Does not look normal, skewed to the left
ggAcf(res) + ggtitle("ACF of residuals") #dashed blue line would give 95% confidence interval. Cannot reject the null of no serial correlation
#use h=10 for non-seasonal data, h=2m for seasonal data, eg monthly seasonality h=24, h=T/5 when is >T/5
Box.test(res,lag=10,fitdf=0) #p=0.385 is high, cannot reject null hypothesis of no serial correlation
Box.test(res,lag=10,fitdf=0,type="Lj") #p=0.3507
dj2 <- window(dj, end=250)
autoplot(dj2) + xlab("Day") + ylab("") +
ggtitle("Dow Jones Index (daily ending 15 Jul 94)")
res <- residuals(naive(dj2)) #et = yt-yt-1
autoplot(res) + xlab("Day") + ylab("") +
ggtitle("Residuals from naive method") #looks random, no seasonality. residual mean close to zero
gghistogram(res) + ggtitle("Histogram of residuals") #Does not look normal, skewed to the left
#use h=10 for non-seasonal data, h=2m for seasonal data, eg monthly seasonality h=24, h=T/5 when is >T/5
Box.test(res,lag=10,fitdf=0) #p=0.385 is high, cannot reject null hypothesis of no serial correlation
Box.test(res,lag=10,fitdf=0,type="Lj") #p=0.3507
checkresiduals(naive(dj2)) #plot residuals, ggAcf, histogram, and Box test
window(ausbeer,start=1995) #quarterly data
subset(ausbeer, start=length(ausbeer)-4*5) #extracts last 5 years of data
length(ausbeer)
beer2 <- window(ausbeer,start=1992,end=c(2007,4)) #Defining training set from 1992Q1 to 2007Q4; Use 2008Q1 to 2010Q2 for test set
beerfit1 <- meanf(beer2,h=10) #fit mean model + forecast 10 periods ahead
?meanf
beerfit2 <- rwf(beer2,h=10) #fit random walk model +forecast 10 periods ahead
beerfit3 <- snaive(beer2,h=10) #fit seasonally-naive + forecast 10 periods ahead
autoplot(window(ausbeer,start = 1992)) +
forecast::autolayer(beerfit1$mean,series="Mean") +
forecast::autolayer(beerfit2$mean,series="Naive") +
forecast::autolayer(beerfit3$mean,series="Seasonal naive")+
xlab("Year") + ylab("Megalitres") +
ggtitle("Forecast for quarterly beer production") +
guides(colour=guide_legend(title="Forecast"))
beer3 <- window(ausbeer,start=2008) #Test set
accuracy(beerfit1,beer3)
accuracy(beerfit2,beer3)
accuracy(beerfit3,beer3)
rbind(accuracy(meanf(beer2,h=10),beer3)[2,c(2,3,5,6)],
accuracy(rwf(beer2,h=10), beer3)[2,c(2,3,5,6)],
accuracy(snaive(beer2,h=10), beer3)[2,c(2,3,5,6)])
#Rolling forecast because the "origin" (k+i-1) at which the forecast is based rolls forward in time
e <- tsCV(dj,rwf,drift=TRUE,h=1) #a list of 1-step ahead rolling forecast error
sqrt(mean(e^2,na.rm=TRUE)) #omit any missing oberservations, RMSE using cross validation
e
sqrt(mean(e^2,na.rm=TRUE)) #omit any missing oberservations, RMSE using cross validation
sqrt(mean(residuals(rwf(dj,drift=TRUE))^2,na.rm=TRUE)) #RMSE of residuals is larger than with CV
dj
rwf(dj,drift=TRUE)
sqrt(mean(residuals(rwf(dj,drift=TRUE, h=10))^2,na.rm=TRUE)) #RMSE of residuals is smaller than with CV
sqrt(mean(residuals(rwf(dj,drift=TRUE, h=20))^2,na.rm=TRUE)) #RMSE of residuals is smaller than with CV, h= 10 is default
uschange #quarterly data of US macroeconomic data
autoplot(uschange[,c("Consumption","Income")]) +
ylab("% change") + xlab("Year")
#consumption as y variable, income as x variable
tslm(Consumption ~ Income, data=uschange) #timeseries linear model
uschange%>%
as.data.frame() %>%
ggplot(aes(x=Income, y=Consumption)) +
ggtitle("Plot of consumption vs Income and the fitted regression line") +
ylab("Consumption (quarterly % change)") +
xlab("Income (quarterly % change)") +
geom_point() + #give us the dots
geom_smooth(method="lm", se=FALSE) #give us the linear regression line
ggplot(aex(x=Income, y=Consumption), data = uschange)
ggplot(aes(x=Income, y=Consumption), data = uschange)
ggplot(income, consumption)
uschange%>%
as.data.frame() %>%
ggplot(aes(x=Income, y=Consumption)) +
ggtitle("Plot of consumption vs Income and the fitted regression line") +
ylab("Consumption (quarterly % change)") +
xlab("Income (quarterly % change)") +
geom_point() + #give us the dots
geom_smooth(method="lm", se=FALSE) #give us the linear regression line
?ggplot
ggplot(uschange, aes(x=Income, y=Consumption))
ggplot(uschange)
?ggplot
uschange <- data.frame(uschange)
ggplot(uschange, aes(x=Income, y=Consumption))
uschange%>%
as.data.frame() %>%
ggplot(aes(x=Income, y=Consumption)) +
ggtitle("Plot of consumption vs Income and the fitted regression line") +
ylab("Consumption (quarterly % change)") +
xlab("Income (quarterly % change)") +
geom_point() + #give us the dots
geom_smooth(method="lm", se=FALSE) #give us the linear regression line
uschange
autoplot(uschange[,c(2,3,4,5)], facets = TRUE) + #can type column number or column name
ylab("% chage") + xlab("Year") #facets = true give us corresponding scale of axis
autoplot(uschange[,c(2,3,4,5)], facets = TRUE) + #can type column number or column name
ylab("% chage") + xlab("Year") #facets = true give us corresponding scale of axis
View(uschange)
View(fc2)
View(uschange)
rm(uschange)
autoplot(uschange[,c(2,3,4,5)], facets = TRUE) + #can type column number or column name
ylab("% chage") + xlab("Year") #facets = true give us corresponding scale of axis
plot(uschange$Income, uschange$Consumption)
uschange <- data.frame(uschange)
> plot(uschange$Income, uschange$Consumption)
plot(uschange$Income, uschange$Consumption)
ggplot(aes(x=uschange$Income, y=uschange$Consumption))
ggplot(aes(x=Income, y=Consumption))
plot(uschange$Income, uschange$Consumption) + geom_point()
uschange%>%
as.data.frame() %>%
ggplot(aes(x=Income, y=Consumption)) +
ggtitle("Plot of consumption vs Income and the fitted regression line") +
ylab("Consumption (quarterly % change)") +
xlab("Income (quarterly % change)") +
geom_point() + #give us the dots
geom_smooth(method="lm", se=FALSE) #give us the linear regression line
rm(uschange)
autoplot(uschange[,c(2,3,4,5)], facets = TRUE) + #can type column number or column name
ylab("% chage") + xlab("Year") #facets = true give us corresponding scale of axis
uschange %>%
as.data.frame() %>%
GGally::ggpairs() #can see that some of the predictor variables are highly correlated. eg, savings and income
fit.consMR <- tslm(Consumption ~ Income + Production +
Unemployment + Savings, data=uschange) #fit an object after running a regression
summary(fit.consMR) #if p value is small (less than significance value), the predictor is statistifically significant
#Use training set to get the model, then use the regression model for the test set
autoplot(uschange[,'Consumption'], series="Data") + #series provides legend
forecast::autolayer(fitted(fit.consMR), series="Fitted") + #fitted extracts fitted values from objects returned by modelling functions
xlab("Year") + ylab("") +
ggtitle("Percentage change in US consumption expenditure") +
guides(colour=guide_legend(title=" "))
cbind(Data=uschange[,"Consumption"], Fitted=fitted(fit.consMR)) %>%
as.data.frame() %>% #store table of data as object
ggplot(aes(x=Data, y=Fitted)) +
geom_point() + #actual data points
xlab("Fitted (predicted values)") +
ylab("Data (actual values") +
ggtitle("Percentage change in US Consumption expenditure") +
geom_abline(intercept=0, slope=1) #45deg line, if good model then the points should be in the line
setwd("C:/Users/cmok1/Desktop/Course material/Y3S2/HE3022/Assignments/Assignment 2")
library(fpp2)
daily20 <- head(elecdaily,20)
#Plot the data and find the regression model with temperature as an explanatory variable
autolot(daily20, facets=TRUE)
#Plot the data and find the regression model with temperature as an explanatory variable
autoplot(daily20, facets=TRUE)
daily20 %>%
as.data.frame(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
ggplot((aes(x=Temperature, y=Demand)) +
geom_smooth(method="lm", se=FALSE)
geom_smooth(method="lm", se=FALSE)
daily20 %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
#Plot the data and find the regression model with temperature as an explanatory variable
autoplot(daily20[,c(Demand, Temperature)], facets=TRUE)
#Plot the data and find the regression model with temperature as an explanatory variable
autoplot(daily20[,c(1, 3)], facets=TRUE)
daily20 %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
#Plot the data and find the regression model with temperature as an explanatory variable
autoplot(daily20[,c(1, 3)], facets=TRUE)
autoplot(daily20, facets=TRUE)
fit <- tslm(Demand ~ Temperature, data=daily20)
#Produce a residual plot, is the model adequate? Are there any outliers?
checkresiduals(fit)
daily20 %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
#I think that the model is adequate since it seems that the residuals are not correlated with each other at 5% significance level as observed in the ACF plot.  However, the residuals
#However, the residuals are clearly not normally distributed so it provides evidence that there is an outlier in the model which affects the slope of the regression line
cbind(Data=daily20[,"Demand"], Fitted=fitted(fit)) %>%
as.data.frame() %>%
ggplot(aes(x=Data, y=Fitted)) +
geom_point() +
geom_abline(intercept=0, slope=1)
#I think that the model is adequate since it seems that the residuals are not correlated with each other at 5% significance level as observed in the ACF plot.  However, the residuals
#However, the residuals are clearly not normally distributed so it provides evidence that there is an outlier in the model which affects the slope of the regression line
cbind(Data=daily20[,"Demand"], Fitted=fitted(fit)) %>%
as.data.frame() %>%
ggplot(aes(x=Data, y=Fitted)) +
geom_point() +
xlab("Data actual values") +
ylab("Fitted predicted values") +
ggtitle("Electricity demand") +
geom_abline(intercept=0, slope=1)
#Scenario-based forecasting
newdata <- data.frame(Temperature = c(15,35))
forecast(fit, newdata=newdata)
daily20 %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
daily20
forecast(fit, newdata=newdata)
predicted <- forecast(fit, newdata=newdata)
predicted
#Repeat using all of available data in elecdaily
elecdaily %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
ylab("Electricity Demand") +
xlab("Temperature") +
geom_point() +
geom_smooth(method="lm", se=FALSE)
View(fit)
#Produce a residual plot, is the model adequate? Are there any outliers?
checkresiduals(fit)
#I think that the model is adequate since it seems that the residuals are not correlated with each other at 5% significance level as observed in the ACF plot.  However, the residuals
#However, the residuals are clearly not normally distributed so it provides evidence that there is an outlier in the model which affects the slope of the regression line
cbind(Data=daily20[,"Demand"], Fitted=fitted(fit)) %>%
as.data.frame() %>%
ggplot(aes(x=Data, y=Fitted)) +
geom_point() +
xlab("Data actual values") +
ylab("Fitted predicted values") +
ggtitle("Electricity demand") +
geom_abline(intercept=0, slope=1)
predicted
#Repeat using all of available data in elecdaily
elecdaily %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
ylab("Electricity Demand") +
xlab("Temperature") +
geom_point() +
geom_smooth(method="lm", se=FALSE)
summary(fit)
View(daily20)
daily20 %>%
as.data.frame() %>%
ggplot(aes(x=Temperature, y=Demand)) +
geom_point() +
geom_smooth(method="lm", se=FALSE)
#Plot the data and find the regression model with temperature as an explanatory variable
autoplot(daily20, facets=TRUE)
#Produce a residual plot, is the model adequate? Are there any outliers?
checkresiduals(fit)
boxplot(daily20)
boxplot(daily20$Temperature)
boxplot(daily20[,"Temperature"])
?boxplot
boxplot(daily20, sep = ".")
boxplot(daily20[,"Temperature"])
boxplot(daily20[,"Temperature"])
boxplot(daily20[,"Demand"])
mean(daily20[,"Demand"])
boxplot(daily20)
boxplot(daily20[,"Demand"])
boxplot(residuals(predicted))
boxplot(residuals(fit))
summary(elecdemand$Demand)
summary(elecdemand[,"Demand"])
elecdemand[,'Demand']
summary(daily20[,"Demand"])
boxplot(elecdemand)
boxplot(elecdemand[,"Demand"])
df <- as.data.frame(daily20)
df[,"residuals"] <- as.numeric(residuals(fit))
ggplot(df, aes(x=Temperature, y=Residuals))
ggplot(df, aes(x=Temperature, y=residuals))
ggplot(df, aes(x=Temperature, y=residuals)) + geom_point()
ggplot(df, aes(x=Temperature, y=residuals)) + geom_point() + geom_smooth()
ggplot(df, aes(x=Demand, y=residuals)) + geom_point() + geom_smooth()
?geom_smooth
ggplot(df, aes(x=Temperature, y=residuals)) + geom_point() + geom_smooth(method="lm")
ggplot(df, aes(x=Demand, y=residuals)) + geom_point() + geom_smooth(method="lm")
#I think that the model is adequate since it seems that the residuals are not correlated with each other at 5% significance level as observed in the ACF plot.  However, the residuals
#However, the residuals are clearly not normally distributed so it provides evidence that there is an outlier in the model which affects the slope of the regression line
cbind(Data=daily20[,"Demand"], Fitted=fitted(fit)) %>%
as.data.frame() %>%
ggplot(aes(x=Data, y=Fitted)) +
geom_point() +
xlab("Data actual values") +
ylab("Fitted predicted values") +
ggtitle("Electricity demand") +
geom_abline(intercept=0, slope=1)
boxplot(daily20[,"Demand"])
ggplot(df, aes(x=Demand, y=residuals)) + geom_point() + geom_smooth(method="lm")
ggplot(df, aes(x=Temperature, y=residuals)) + geom_point() + geom_smooth(method="lm")
